{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "194265d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import os\n",
    "#import sklearn\n",
    "from sklearn import svm\n",
    "import joblib   #用于保存模型\n",
    "from scipy.cluster.vq import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecfcf0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and save model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classfication.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预处理\n",
    "train_path = \"Dataset/train/\"\n",
    "training_names = os.listdir(train_path)\n",
    "image_paths = []   #字符串形式存储每张图片路径\n",
    "image_classes = []  #存储类标\n",
    "class_id = 0\n",
    "for training_name in training_names:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    #class_path = imutils.imlist(dir)\n",
    "    class_path = [os.path.join(dir, f) for f in os.listdir(dir)]\n",
    "    image_paths += class_path                       #存储所有图片\n",
    "    image_classes += [class_id] * len(class_path)    #存储图片对应类标\n",
    "    class_id += 1\n",
    "    \n",
    "    \n",
    "# 创建SIFT特征提取器\n",
    "sift = cv2.SIFT_create()\n",
    "# 特征提取与描述子生成\n",
    "des_list = []\n",
    "for image_path in image_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    im = cv2.resize(im, (256, 256))\n",
    "    kpts = sift.detect(im)\n",
    "    kpts, des = sift.compute(im, kpts)\n",
    "    des_list.append((image_path, des))\n",
    "    #print(\"image file path : \", image_path)\n",
    "# 描述子向量\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "# 100 聚类 K-Means\n",
    "k = 100\n",
    "voc, variance = kmeans(descriptors, k, 1)\n",
    "# 生成特征直方图\n",
    "im_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    words, distance = vq(des_list[i][1], voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "        \n",
    "# 实现动词词频与出现频率统计\n",
    "nbr_occurences = np.sum((im_features > 0) * 1, axis=0)\n",
    "idf = np.array(np.log((1.0 * len(image_paths) + 1) / (1.0 * nbr_occurences + 1)), 'float32')\n",
    "\n",
    "# 尺度化\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n",
    "# Train the Linear SVM\n",
    "\n",
    "\n",
    "#模型融合\n",
    "clf0 = svm.LinearSVC(dual=False)  ##准确的0.6左右\n",
    "clf1 = svm.SVC(gamma=0.001)  #准确的0.4左右\n",
    "clf2 = KNeighborsClassifier(n_neighbors=30)   #0.46\n",
    "clf3 = GradientBoostingClassifier(n_estimators=100,max_features=16, random_state=4869) #0.53\n",
    "clf4 = RandomForestClassifier(n_estimators=100, random_state=2022, n_jobs=-1)  #0.5\n",
    "final_estimator = GradientBoostingClassifier(n_estimators=200,max_features=16, random_state=4869)\n",
    "estimators = [(\"LSVC\",clf0),\n",
    "              (\"SVC\",clf1),\n",
    "              (\"KNN\",clf2),\n",
    "              (\"GBC\",clf3),\n",
    "              (\"RCF\",clf4)\n",
    "                ]\n",
    "clf = StackingClassifier(estimators=estimators,final_estimator=final_estimator,n_jobs=-1,stack_method='predict' ,passthrough=True).fit(im_features, np.array(image_classes))\n",
    "\n",
    "\n",
    "#此为单独使用GradientBoostingClassifier的版本，准确率0.5左右\n",
    "#clf = GradientBoostingClassifier(n_estimators=100,max_features=16, random_state=4869).fit(im_features, np.array(image_classes))\n",
    "\n",
    "\n",
    "# 保存模型\n",
    "print(\"training and save model...\")\n",
    "joblib.dump((clf, training_names, stdSlr, k, voc), \"classfication.pkl\", compress=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81199e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
